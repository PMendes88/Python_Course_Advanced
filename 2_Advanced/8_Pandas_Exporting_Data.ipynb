{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6605e90c",
   "metadata": {},
   "source": [
    "# Pandas: Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74a3b0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading Datadataset \n",
    "dataset = load_dataset('lukebarousse/data_jobs')\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# Data Cleanup\n",
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d977324",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_posted_month'] = df['job_posted_date'].dt.strftime('%b')\n",
    "months = df['job_posted_month'].unique()\n",
    "{month: month for month in months}\n",
    "{month: df[df['job_posted_month'] == month] for month in months}\n",
    "dict_months = {month: df[df['job_posted_month'] == month] for month in months}\n",
    "pd.concat([dict_months['Jan'], dict_months['Feb'], dict_months['Mar']], ignore_index=True)\n",
    "df_q1 = pd.concat([dict_months['Jan'], dict_months['Feb'], dict_months['Mar']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c7f4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q1.head().to_clipboard(sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822b3c95",
   "metadata": {},
   "source": [
    ",job_title_short,job_title,job_location,job_via,job_schedule_type,job_work_from_home,search_location,job_posted_date,job_no_degree_mention,job_health_insurance,job_country,salary_rate,salary_year_avg,salary_hour_avg,company_name,job_skills,job_type_skills,job_posted_month\n",
    "0,Data Analyst,Data Analyst,\"Guadalajara, Jalisco, Mexico\",via BeBee México,Full-time,False,Mexico,2023-01-14 13:18:07,False,False,Mexico,,,,Hewlett Packard Enterprise,\"['r', 'python', 'sql', 'nosql', 'power bi', 'tableau']\",\"{'analyst_tools': ['power bi', 'tableau'], 'programming': ['r', 'python', 'sql', 'nosql']}\",Jan\n",
    "1,Data Scientist,Data Scientist,\"Zaventem, Belgium\",via BeBee Belgique,Full-time,False,Belgium,2023-01-31 13:53:38,False,False,Belgium,,,,Devoteam,\"['r', 'python', 'sql', 'pandas', 'numpy', 'scikit-learn', 'matplotlib', 'hadoop', 'spark']\",\"{'libraries': ['pandas', 'numpy', 'scikit-learn', 'matplotlib', 'hadoop', 'spark'], 'programming': ['r', 'python', 'sql']}\",Jan\n",
    "2,Data Engineer,Data Engineer,\"Fort Worth, TX\",via LinkedIn,Full-time,False,\"Texas, United States\",2023-01-25 13:24:01,False,False,United States,,,,Programmers.io,\"['sql', 'python']\",\"{'programming': ['sql', 'python']}\",Jan\n",
    "3,Data Engineer,Data Engineer,\"San Mateo, CA\",via LinkedIn,Full-time,False,\"California, United States\",2023-01-28 13:07:30,False,True,United States,,,,Verkada,\"['sql', 'python', 'aws', 'looker']\",\"{'analyst_tools': ['looker'], 'cloud': ['aws'], 'programming': ['sql', 'python']}\",Jan\n",
    "4,Data Scientist,Data Scientist,\"São Paulo, State of São Paulo, Brazil\",via BeBee,Full-time,False,Brazil,2023-01-03 23:02:27,False,False,Brazil,,,,Mars,\"['python', 'sql', 'azure']\",\"{'cloud': ['azure'], 'programming': ['python', 'sql']}\",Jan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d990a3c",
   "metadata": {},
   "source": [
    "# Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac2c3910",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q1.to_csv('quarter_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('quarter_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf011e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('quarter_1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b8d3d0",
   "metadata": {},
   "source": [
    "# Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3dd69b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q1.to_excel('quarter_1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b89a98",
   "metadata": {},
   "source": [
    "# Export to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622ddf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite://jobs.db')\n",
    "\n",
    "df.to_sql('job_table', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f0e1e2",
   "metadata": {},
   "source": [
    "# Export to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10049e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('jobs_data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c7f836",
   "metadata": {},
   "source": [
    "# Export to Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d823baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('job_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
